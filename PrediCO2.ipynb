{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9f0ec4-552d-4614-88a1-acd97f035649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input,Dense,LSTM,Dropout,MultiHeadAttention,LayerNormalization\n",
    "from tensorflow.keras.losses import MeanSquaredError,MeanAbsoluteError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping\n",
    "\n",
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1b071f",
   "metadata": {},
   "source": [
    "## you could delete this line here (os one)\n",
    "- i needed it cause im using wsl for tensorflow, but in normal windows, its possible to remove it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c423fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/tf-acno-projects/Project-Data-Mining')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25d3382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_y_forecasting_splits(Datafile,time_steps):\n",
    "    X,y = list(),list()\n",
    "    for start in range(len(Datafile)):\n",
    "        end = start+time_steps \n",
    "        if end>len(Datafile)-1:\n",
    "            break\n",
    "        X.append(Datafile.iloc[start:end].values)\n",
    "        y.append(Datafile.iloc[end][\"CO2 Emission\"])\n",
    "    return np.array(X),np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8d14c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def months_converter(DataFile):\n",
    "    unique_months = DataFile['Month'].unique()\n",
    "    months_dict = {\n",
    "        month:idx+1 for idx,month in enumerate(unique_months)\n",
    "    }\n",
    "    DataFile['Month'] = DataFile['Month'].map(months_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc50550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_architecture(input_shape,lr):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    hidden_layer = LSTM(64)(input_layer)\n",
    "    hidden_layer = Dense(32,activation='relu')(hidden_layer)\n",
    "    hidden_layer = Dense(16,activation='relu')(hidden_layer)\n",
    "    output_layer = Dense(1,activation='linear')(hidden_layer)\n",
    "\n",
    "    lstm_model = Model(input_layer,output_layer)\n",
    "    lstm_model.compile(optimizer=Adam(learning_rate=lr),loss=MeanSquaredError(),metrics=[MeanAbsoluteError()])\n",
    "    return lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227e9c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(sequence_length,d_model,n=10000):\n",
    "    \"\"\"\n",
    "    - d_model: the dimension of our input ( output of the embedding space )\n",
    "    - sequence_length: the length of our sequence for example we have 3 features then its 3\n",
    "    \"\"\"\n",
    "    PosEnc = np.zeros((sequence_length,d_model))\n",
    "    indices = np.arange(int(d_model/2))\n",
    "    positions = np.arange((sequence_length))\n",
    "    \n",
    "    for position in positions:\n",
    "        for index in indices:\n",
    "            denomenator = np.power(n,2*index/d_model)\n",
    "            PosEnc[position,2*index] = np.sin(position/denomenator)\n",
    "            PosEnc[position,2*index+1] = np.cos(position/denomenator)\n",
    "\n",
    "    pos_enc_tensor = tf.constant(PosEnc, dtype=tf.float32)\n",
    "    pos_enc_tensor = tf.reshape(pos_enc_tensor, (1, sequence_length, d_model))\n",
    "    return pos_enc_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debdefbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_embedding_positioning(sequence_length,d_model,input_layer):\n",
    "    \"\"\"\n",
    "    - We use **the embedding** which is a way to convert raw input into a high-dimensional vector (d_model in this case).\n",
    "        so our embedding vector shape is **(batch_size,time,features_embedding)**\n",
    "    - **Positional encoding** is added to this embedding vector so the model knows about the position of each token or feature.\n",
    "    \"\"\"\n",
    "    x_embedded = Dense(d_model)(input_layer)\n",
    "    pos_enc = positional_encoding(sequence_length,d_model)\n",
    "    return x_embedded + pos_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b794fb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_encoder(x,d_model,num_heads,key_dim):\n",
    "    attention_layer = MultiHeadAttention(num_heads=num_heads,key_dim=key_dim)(x,x)\n",
    "    add_norm1 = LayerNormalization(epsilon=1e-6)(x+attention_layer)\n",
    "    \n",
    "    feed_forward_input = Dense(d_model*2,activation='relu')(add_norm1)\n",
    "    feed_forward_output = Dense(d_model)(feed_forward_input)\n",
    "    add_norm2 = LayerNormalization(epsilon=1e-6)(add_norm1+feed_forward_output)\n",
    "    \n",
    "    return add_norm2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc07bb9",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <img src=\"static/encoder_transformer.png\" width=\"300\" height=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "54bc78b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_architecture(input_shape,lr,sequence_length,d_model,num_heads,key_dim):   \n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x_positioned_embedded = transformer_embedding_positioning(sequence_length,d_model,input_layer) \n",
    "    x1 = transformer_encoder(x_positioned_embedded,d_model,num_heads,key_dim)\n",
    "    x2 = transformer_encoder(x1,d_model,num_heads,key_dim)\n",
    "    output_layer = Dense(1)(x2)\n",
    "    \n",
    "    transformer = Model(input_layer,output_layer)\n",
    "    transformer.compile(optimizer=Adam(learning_rate=lr),loss=MeanSquaredError(),metrics=[MeanAbsoluteError()])\n",
    "    return transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39daf82a-f82a-45c0-a62c-e820fde8b442",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFile = pd.read_csv(\"Emission.csv\")\n",
    "DataFile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3c1467-6b63-40db-ad7c-9c75f8297757",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DataFile.isnull().sum())\n",
    "print(DataFile.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269d0dc9-ce40-4e53-b339-6b6cf108aac8",
   "metadata": {},
   "source": [
    "Alright, there are no null values and no duplicates but there is something wrong with the \"Year-Month\" column, it's better to split it into two and convert them to numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf323fe-847b-4303-926a-454baf775a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFile[['Year', 'Month']] = DataFile['Year-Month'].str.split('-', expand=True)\n",
    "\n",
    "DataFile.drop(columns=['Year-Month'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0154ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "months_converter(DataFile)\n",
    "\n",
    "for col in DataFile.columns:\n",
    "    DataFile[col] = pd.to_numeric(DataFile[col],errors='coerce')\n",
    "print(DataFile)\n",
    "print(DataFile.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2830b789",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dataset Min : {DataFile[\"CO2 Emission\"].min()}')\n",
    "print(f'Dataset Max : {DataFile[\"CO2 Emission\"].max()}')\n",
    "print(f'Dataset Mean : {DataFile[\"CO2 Emission\"].mean()}')\n",
    "print(f'Dataset STD : {DataFile[\"CO2 Emission\"].std()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26029c1f",
   "metadata": {},
   "source": [
    "this is a note that we should scale the data later on for our models so we could detect overfitting or underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c41f3b-0ffb-4a21-ba5b-8f894b0ed742",
   "metadata": {},
   "source": [
    "Now we need to perform visual analysis on our dataset, but first we need to create a csv of our new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3690acd5-0369-49cf-b1ba-1fef274c93c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFile.to_csv(\"New Emission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe38774-4f7d-494c-bd52-8fb179be787e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFile = pd.read_csv(\"New Emission.csv\")\n",
    "\n",
    "DataFile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9019b6-bab1-49cd-94a6-8a9a7abbb43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(DataFile[\"Year\"], DataFile[\"CO2 Emission\"], marker=\"o\", linestyle=\"-\", color=\"b\")\n",
    "\n",
    "# Labels and Title\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"CO2 Emission (ppm)\")\n",
    "plt.title(\"CO2 Emission Over the Years\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee544538-e546-4aae-97a5-c26c8014acf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=DataFile[\"Month\"], y=DataFile[\"CO2 Emission\"], palette=\"coolwarm\")\n",
    "\n",
    "# Labels and Title\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"CO2 Emission (ppm)\")\n",
    "plt.title(\"CO2 Emission by Month\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48417bf-3df5-41db-85cd-94d73c8efc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "sns.barplot(x=DataFile[\"Year\"], y=DataFile[\"CO2 Emission\"], palette=\"coolwarm\")\n",
    "\n",
    "# Labels and Title\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"CO2 Emission (ppm)\")\n",
    "plt.title(\"CO2 Emission by Year\")\n",
    "\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e06e71d-27d9-4ad8-87a8-915ffe21ac25",
   "metadata": {},
   "source": [
    "It's kind of a complex figure so we will group the years into ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809b68c8-bfbe-494a-92a0-f9ff70464ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_year = DataFile[\"Year\"].min()\n",
    "max_year = DataFile[\"Year\"].max()\n",
    "\n",
    "print(min_year)\n",
    "print(max_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57cc83e-dbd7-4483-aa0b-1370dc69ec7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [1970, 1975, 1980, 1985, 1990, 1995, 2000, 2005, 2010, 2015]\n",
    "\n",
    "labels = [\"1971-1975\", \"1976-1980\", \"1981-1985\", \"1986-1990\", \"1991-1995\", \"1996-2000\", \"2001-2005\", \"2006-2010\", \"2011-2015\"]\n",
    "\n",
    "DataFile[\"Year Range\"] = pd.cut(DataFile[\"Year\"], bins=bins, labels=labels, right=True)\n",
    "print(DataFile[[\"Year\", \"Year Range\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2077229-454a-42e6-a1f9-7d5fbbec345c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))  # Increase width\n",
    "sns.barplot(x=DataFile[\"Year Range\"], y=DataFile[\"CO2 Emission\"], palette=\"coolwarm\")\n",
    "\n",
    "plt.xlabel(\"Year Range\")\n",
    "plt.ylabel(\"CO2 Emission (ppm)\")\n",
    "plt.title(\"CO2 Emission by Year\")\n",
    "\n",
    "plt.xticks(rotation=45, ha=\"right\")  # Rotate labels for better spacing\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3900c72-e2b4-4024-b223-e6ee6e974516",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFile.drop(columns=['Year Range'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daea0655",
   "metadata": {},
   "source": [
    "## LSTM AND TRANSFORMERS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87e1dd3",
   "metadata": {},
   "source": [
    "We have 486 rows so :\n",
    "- train 80% = int(len(DataFile)*0.8)+1 => 389\n",
    "- test 10% =  int(len(DataFile)*0.1) => 48\n",
    "- validation 10% = int(len(DataFile)*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f632a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_STEP = 3\n",
    "X,y = X_y_forecasting_splits(DataFile,TIME_STEP)\n",
    "scaler = MinMaxScaler()\n",
    "y_scaled = scaler.fit_transform(y.reshape(-1,1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c24b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (TIME_STEP,3) # (time_step, features)\n",
    "LR = 0.1\n",
    "EPOCHS = 80\n",
    "N_SPLITS = 3\n",
    "CALLBACK = [\n",
    "    ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,\n",
    "    patience=20,\n",
    "    min_delta=0.0005,\n",
    "    min_lr=1e-6,\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=20,\n",
    "    min_delta=0.0001,\n",
    "    )]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54fe593",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53b7ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_split_folds = TimeSeriesSplit(n_splits=N_SPLITS)\n",
    "performance = []\n",
    "for fold ,(training_idx, validation_idx) in enumerate(time_series_split_folds.split(X,y)):\n",
    "    lstm_model = lstm_architecture(INPUT_SHAPE,LR)\n",
    "\n",
    "    X_train_cv = tf.convert_to_tensor(X[training_idx], dtype=tf.float32)\n",
    "    X_val_cv = tf.convert_to_tensor(X[validation_idx], dtype=tf.float32)\n",
    "    y_train_cv = tf.convert_to_tensor(y_scaled[training_idx], dtype=tf.float32)\n",
    "    y_val_cv = tf.convert_to_tensor(y_scaled[validation_idx], dtype=tf.float32)\n",
    "    \n",
    "    train_start = perf_counter()\n",
    "    history = lstm_model.fit(X_train_cv,y_train_cv,epochs=EPOCHS,validation_data=(X_val_cv,y_val_cv),callbacks=CALLBACK,verbose=0)\n",
    "    train_end = perf_counter()\n",
    "    \n",
    "    val_loss, val_mae = lstm_model.evaluate(X_val_cv, y_val_cv,verbose=0)\n",
    "    \n",
    "    y_val_preds_scaled = lstm_model.predict(X_val_cv)\n",
    "    y_val_preds_original = scaler.inverse_transform(y_val_preds_scaled).flatten()\n",
    "    y_val_original = scaler.inverse_transform(y_val_cv.numpy().reshape(-1,1)).flatten()\n",
    "    \n",
    "    # Calculating the metrics :\n",
    "    y_mean = np.mean(y_val_original)\n",
    "    mae_original = np.mean(np.abs(y_val_preds_original - y_val_original))\n",
    "    mape_calculated = np.mean(np.abs((y_val_preds_original - y_val_original) / y_val_original)) # mape = 1/n * sum( abs(y_real - y_predicted) )\n",
    "    \n",
    "    sce = np.sum((y_val_preds_original - y_mean) ** 2)\n",
    "    sst = np.sum((y_val_original - y_mean) ** 2)\n",
    "    r2_calculated = sce / sst # r2 = SCE / SST\n",
    "    \n",
    "    performance.append({\n",
    "    \"fold\": fold,\n",
    "    \"loss\": f'{history.history[\"loss\"]}',\n",
    "    \"mae\": f'{history.history[\"mean_absolute_error\"]}',\n",
    "    \"val_loss\": f'{history.history[\"val_loss\"]}',\n",
    "    \"val_mae_scaled\": f'{history.history[\"val_mean_absolute_error\"]}',\n",
    "    \"val_mae_original\": f'{mae_original:.4f}',\n",
    "    \"r2_calculated\": f'{r2_calculated:.4f}',\n",
    "    \"training_time\": f'{train_end-train_start}'\n",
    "    })    \n",
    "    \n",
    "    print(f'Fold {fold} , val_loss is : {val_loss:.2f}, MAE scaled is : {val_mae:.2f}, MAE original is : {mae_original:.2f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51386a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame(performance)\n",
    "performance.to_csv('lstm_performance.csv')\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c65703",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6d06d7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_MODEL = 64\n",
    "SEQ_LEN = 3\n",
    "\n",
    "NUM_HEADS = 8\n",
    "KEY_DIM = D_MODEL//NUM_HEADS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6e5920ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "4/4 - 8s - loss: 46.2544 - mean_absolute_error: 5.3705 - val_loss: 30.7052 - val_mean_absolute_error: 5.5446 - lr: 0.1000 - 8s/epoch - 2s/step\n",
      "Epoch 2/80\n",
      "4/4 - 0s - loss: 15.1247 - mean_absolute_error: 3.5713 - val_loss: 0.9717 - val_mean_absolute_error: 0.9854 - lr: 0.1000 - 209ms/epoch - 52ms/step\n",
      "Epoch 3/80\n",
      "4/4 - 0s - loss: 0.2690 - mean_absolute_error: 0.4487 - val_loss: 0.2568 - val_mean_absolute_error: 0.4935 - lr: 0.1000 - 214ms/epoch - 53ms/step\n",
      "Epoch 4/80\n",
      "4/4 - 0s - loss: 0.3119 - mean_absolute_error: 0.5332 - val_loss: 0.0151 - val_mean_absolute_error: 0.1076 - lr: 0.1000 - 187ms/epoch - 47ms/step\n",
      "Epoch 5/80\n",
      "4/4 - 0s - loss: 0.1505 - mean_absolute_error: 0.3328 - val_loss: 0.7159 - val_mean_absolute_error: 0.8450 - lr: 0.1000 - 199ms/epoch - 50ms/step\n",
      "Epoch 6/80\n",
      "4/4 - 0s - loss: 0.3165 - mean_absolute_error: 0.5209 - val_loss: 0.0237 - val_mean_absolute_error: 0.1357 - lr: 0.1000 - 191ms/epoch - 48ms/step\n",
      "Epoch 7/80\n",
      "4/4 - 0s - loss: 0.1475 - mean_absolute_error: 0.3351 - val_loss: 0.1098 - val_mean_absolute_error: 0.3131 - lr: 0.1000 - 189ms/epoch - 47ms/step\n",
      "Epoch 8/80\n",
      "4/4 - 0s - loss: 0.0925 - mean_absolute_error: 0.2542 - val_loss: 0.2362 - val_mean_absolute_error: 0.4808 - lr: 0.1000 - 202ms/epoch - 50ms/step\n",
      "Epoch 9/80\n",
      "4/4 - 0s - loss: 0.1199 - mean_absolute_error: 0.3281 - val_loss: 0.0412 - val_mean_absolute_error: 0.1866 - lr: 0.1000 - 192ms/epoch - 48ms/step\n",
      "Epoch 10/80\n",
      "4/4 - 0s - loss: 0.0538 - mean_absolute_error: 0.2072 - val_loss: 0.0188 - val_mean_absolute_error: 0.1038 - lr: 0.1000 - 181ms/epoch - 45ms/step\n",
      "Epoch 11/80\n",
      "4/4 - 0s - loss: 0.0345 - mean_absolute_error: 0.1590 - val_loss: 0.1540 - val_mean_absolute_error: 0.3850 - lr: 0.1000 - 191ms/epoch - 48ms/step\n",
      "Epoch 12/80\n",
      "4/4 - 0s - loss: 0.0352 - mean_absolute_error: 0.1561 - val_loss: 0.0105 - val_mean_absolute_error: 0.0890 - lr: 0.1000 - 195ms/epoch - 49ms/step\n",
      "Epoch 13/80\n",
      "4/4 - 0s - loss: 0.0261 - mean_absolute_error: 0.1403 - val_loss: 0.0246 - val_mean_absolute_error: 0.1385 - lr: 0.1000 - 179ms/epoch - 45ms/step\n",
      "Epoch 14/80\n",
      "4/4 - 0s - loss: 0.0119 - mean_absolute_error: 0.0899 - val_loss: 0.0637 - val_mean_absolute_error: 0.2385 - lr: 0.1000 - 204ms/epoch - 51ms/step\n",
      "Epoch 15/80\n",
      "4/4 - 0s - loss: 0.0114 - mean_absolute_error: 0.0828 - val_loss: 0.0122 - val_mean_absolute_error: 0.0960 - lr: 0.1000 - 195ms/epoch - 49ms/step\n",
      "Epoch 16/80\n",
      "4/4 - 0s - loss: 0.0087 - mean_absolute_error: 0.0749 - val_loss: 0.0567 - val_mean_absolute_error: 0.2238 - lr: 0.1000 - 195ms/epoch - 49ms/step\n",
      "Epoch 17/80\n",
      "4/4 - 0s - loss: 0.0094 - mean_absolute_error: 0.0772 - val_loss: 0.0214 - val_mean_absolute_error: 0.1285 - lr: 0.1000 - 191ms/epoch - 48ms/step\n",
      "Epoch 18/80\n",
      "4/4 - 0s - loss: 0.0074 - mean_absolute_error: 0.0665 - val_loss: 0.0305 - val_mean_absolute_error: 0.1563 - lr: 0.1000 - 207ms/epoch - 52ms/step\n",
      "Epoch 19/80\n",
      "4/4 - 0s - loss: 0.0069 - mean_absolute_error: 0.0668 - val_loss: 0.0337 - val_mean_absolute_error: 0.1657 - lr: 0.1000 - 189ms/epoch - 47ms/step\n",
      "Epoch 20/80\n",
      "4/4 - 0s - loss: 0.0063 - mean_absolute_error: 0.0627 - val_loss: 0.0243 - val_mean_absolute_error: 0.1376 - lr: 0.1000 - 223ms/epoch - 56ms/step\n",
      "Epoch 21/80\n",
      "4/4 - 0s - loss: 0.0064 - mean_absolute_error: 0.0641 - val_loss: 0.0384 - val_mean_absolute_error: 0.1790 - lr: 0.1000 - 269ms/epoch - 67ms/step\n",
      "Epoch 22/80\n",
      "4/4 - 0s - loss: 0.0059 - mean_absolute_error: 0.0606 - val_loss: 0.0226 - val_mean_absolute_error: 0.1321 - lr: 0.1000 - 189ms/epoch - 47ms/step\n",
      "Epoch 23/80\n",
      "4/4 - 0s - loss: 0.0067 - mean_absolute_error: 0.0638 - val_loss: 0.0353 - val_mean_absolute_error: 0.1703 - lr: 0.1000 - 215ms/epoch - 54ms/step\n",
      "Epoch 24/80\n",
      "4/4 - 0s - loss: 0.0059 - mean_absolute_error: 0.0595 - val_loss: 0.0271 - val_mean_absolute_error: 0.1459 - lr: 0.1000 - 199ms/epoch - 50ms/step\n",
      "Epoch 25/80\n",
      "4/4 - 0s - loss: 0.0061 - mean_absolute_error: 0.0603 - val_loss: 0.0361 - val_mean_absolute_error: 0.1725 - lr: 0.1000 - 197ms/epoch - 49ms/step\n",
      "Epoch 26/80\n",
      "4/4 - 0s - loss: 0.0066 - mean_absolute_error: 0.0629 - val_loss: 0.0257 - val_mean_absolute_error: 0.1419 - lr: 0.1000 - 178ms/epoch - 44ms/step\n",
      "Epoch 27/80\n",
      "4/4 - 0s - loss: 0.0066 - mean_absolute_error: 0.0632 - val_loss: 0.0333 - val_mean_absolute_error: 0.1644 - lr: 0.1000 - 208ms/epoch - 52ms/step\n",
      "Epoch 28/80\n",
      "4/4 - 0s - loss: 0.0060 - mean_absolute_error: 0.0603 - val_loss: 0.0322 - val_mean_absolute_error: 0.1614 - lr: 0.1000 - 183ms/epoch - 46ms/step\n",
      "Epoch 29/80\n",
      "4/4 - 0s - loss: 0.0062 - mean_absolute_error: 0.0607 - val_loss: 0.0322 - val_mean_absolute_error: 0.1614 - lr: 0.1000 - 184ms/epoch - 46ms/step\n",
      "Epoch 30/80\n",
      "4/4 - 0s - loss: 0.0064 - mean_absolute_error: 0.0619 - val_loss: 0.0299 - val_mean_absolute_error: 0.1545 - lr: 0.1000 - 184ms/epoch - 46ms/step\n",
      "Epoch 31/80\n",
      "4/4 - 0s - loss: 0.0061 - mean_absolute_error: 0.0615 - val_loss: 0.0303 - val_mean_absolute_error: 0.1556 - lr: 0.1000 - 203ms/epoch - 51ms/step\n",
      "Epoch 32/80\n",
      "4/4 - 0s - loss: 0.0060 - mean_absolute_error: 0.0603 - val_loss: 0.0283 - val_mean_absolute_error: 0.1496 - lr: 0.1000 - 205ms/epoch - 51ms/step\n",
      "4/4 [==============================] - 0s 14ms/step\n",
      "Fold 0 , val_loss is : 0.03, MAE scaled is : 0.15, MAE original is : 12.39\n",
      "Epoch 1/80\n",
      "8/8 - 8s - loss: 34.8562 - mean_absolute_error: 4.8395 - val_loss: 4.6869 - val_mean_absolute_error: 2.1683 - lr: 0.1000 - 8s/epoch - 1s/step\n",
      "Epoch 2/80\n",
      "8/8 - 0s - loss: 2.4705 - mean_absolute_error: 1.4634 - val_loss: 1.2274 - val_mean_absolute_error: 1.0967 - lr: 0.1000 - 319ms/epoch - 40ms/step\n",
      "Epoch 3/80\n",
      "8/8 - 0s - loss: 0.9858 - mean_absolute_error: 0.9162 - val_loss: 2.1107 - val_mean_absolute_error: 1.4549 - lr: 0.1000 - 323ms/epoch - 40ms/step\n",
      "Epoch 4/80\n",
      "8/8 - 0s - loss: 0.4955 - mean_absolute_error: 0.6288 - val_loss: 0.2153 - val_mean_absolute_error: 0.4453 - lr: 0.1000 - 373ms/epoch - 47ms/step\n",
      "Epoch 5/80\n",
      "8/8 - 1s - loss: 0.2384 - mean_absolute_error: 0.4302 - val_loss: 0.7348 - val_mean_absolute_error: 0.8564 - lr: 0.1000 - 522ms/epoch - 65ms/step\n",
      "Epoch 6/80\n",
      "8/8 - 0s - loss: 0.1264 - mean_absolute_error: 0.3085 - val_loss: 0.0118 - val_mean_absolute_error: 0.0914 - lr: 0.1000 - 352ms/epoch - 44ms/step\n",
      "Epoch 7/80\n",
      "8/8 - 0s - loss: 0.0549 - mean_absolute_error: 0.1954 - val_loss: 0.3191 - val_mean_absolute_error: 0.5605 - lr: 0.1000 - 313ms/epoch - 39ms/step\n",
      "Epoch 8/80\n",
      "8/8 - 0s - loss: 0.0377 - mean_absolute_error: 0.1619 - val_loss: 0.0415 - val_mean_absolute_error: 0.1822 - lr: 0.1000 - 298ms/epoch - 37ms/step\n",
      "Epoch 9/80\n",
      "8/8 - 0s - loss: 0.0214 - mean_absolute_error: 0.1195 - val_loss: 0.1949 - val_mean_absolute_error: 0.4342 - lr: 0.1000 - 378ms/epoch - 47ms/step\n",
      "Epoch 10/80\n",
      "8/8 - 0s - loss: 0.0161 - mean_absolute_error: 0.1034 - val_loss: 0.0799 - val_mean_absolute_error: 0.2673 - lr: 0.1000 - 391ms/epoch - 49ms/step\n",
      "Epoch 11/80\n",
      "8/8 - 0s - loss: 0.0153 - mean_absolute_error: 0.1038 - val_loss: 0.1440 - val_mean_absolute_error: 0.3699 - lr: 0.1000 - 446ms/epoch - 56ms/step\n",
      "Epoch 12/80\n",
      "8/8 - 0s - loss: 0.0133 - mean_absolute_error: 0.0969 - val_loss: 0.1018 - val_mean_absolute_error: 0.3063 - lr: 0.1000 - 345ms/epoch - 43ms/step\n",
      "Epoch 13/80\n",
      "8/8 - 0s - loss: 0.0127 - mean_absolute_error: 0.0933 - val_loss: 0.1364 - val_mean_absolute_error: 0.3594 - lr: 0.1000 - 344ms/epoch - 43ms/step\n",
      "Epoch 14/80\n",
      "8/8 - 0s - loss: 0.0132 - mean_absolute_error: 0.0948 - val_loss: 0.1115 - val_mean_absolute_error: 0.3221 - lr: 0.1000 - 376ms/epoch - 47ms/step\n",
      "Epoch 15/80\n",
      "8/8 - 0s - loss: 0.0129 - mean_absolute_error: 0.0946 - val_loss: 0.1167 - val_mean_absolute_error: 0.3302 - lr: 0.1000 - 353ms/epoch - 44ms/step\n",
      "Epoch 16/80\n",
      "8/8 - 0s - loss: 0.0132 - mean_absolute_error: 0.0959 - val_loss: 0.1307 - val_mean_absolute_error: 0.3511 - lr: 0.1000 - 402ms/epoch - 50ms/step\n",
      "Epoch 17/80\n",
      "8/8 - 0s - loss: 0.0130 - mean_absolute_error: 0.0956 - val_loss: 0.1121 - val_mean_absolute_error: 0.3230 - lr: 0.1000 - 419ms/epoch - 52ms/step\n",
      "Epoch 18/80\n",
      "8/8 - 0s - loss: 0.0130 - mean_absolute_error: 0.0946 - val_loss: 0.1163 - val_mean_absolute_error: 0.3296 - lr: 0.1000 - 342ms/epoch - 43ms/step\n",
      "Epoch 19/80\n",
      "8/8 - 0s - loss: 0.0132 - mean_absolute_error: 0.0946 - val_loss: 0.1157 - val_mean_absolute_error: 0.3286 - lr: 0.1000 - 366ms/epoch - 46ms/step\n",
      "Epoch 20/80\n",
      "8/8 - 0s - loss: 0.0135 - mean_absolute_error: 0.0953 - val_loss: 0.1253 - val_mean_absolute_error: 0.3433 - lr: 0.1000 - 294ms/epoch - 37ms/step\n",
      "Epoch 21/80\n",
      "8/8 - 0s - loss: 0.0129 - mean_absolute_error: 0.0932 - val_loss: 0.1054 - val_mean_absolute_error: 0.3123 - lr: 0.1000 - 298ms/epoch - 37ms/step\n",
      "Epoch 22/80\n",
      "8/8 - 0s - loss: 0.0133 - mean_absolute_error: 0.0945 - val_loss: 0.1151 - val_mean_absolute_error: 0.3277 - lr: 0.1000 - 288ms/epoch - 36ms/step\n",
      "Epoch 23/80\n",
      "8/8 - 0s - loss: 0.0129 - mean_absolute_error: 0.0938 - val_loss: 0.1147 - val_mean_absolute_error: 0.3271 - lr: 0.1000 - 301ms/epoch - 38ms/step\n",
      "Epoch 24/80\n",
      "8/8 - 0s - loss: 0.0130 - mean_absolute_error: 0.0968 - val_loss: 0.1397 - val_mean_absolute_error: 0.3639 - lr: 0.1000 - 281ms/epoch - 35ms/step\n",
      "Epoch 25/80\n",
      "8/8 - 0s - loss: 0.0134 - mean_absolute_error: 0.0949 - val_loss: 0.1075 - val_mean_absolute_error: 0.3157 - lr: 0.1000 - 329ms/epoch - 41ms/step\n",
      "Epoch 26/80\n",
      "8/8 - 0s - loss: 0.0128 - mean_absolute_error: 0.0941 - val_loss: 0.1369 - val_mean_absolute_error: 0.3600 - lr: 0.1000 - 312ms/epoch - 39ms/step\n",
      "4/4 [==============================] - 1s 20ms/step\n",
      "Fold 1 , val_loss is : 0.14, MAE scaled is : 0.36, MAE original is : 30.07\n",
      "Epoch 1/80\n",
      "12/12 - 9s - loss: 18.1429 - mean_absolute_error: 2.0110 - val_loss: 1.0439 - val_mean_absolute_error: 1.0102 - lr: 0.1000 - 9s/epoch - 759ms/step\n",
      "Epoch 2/80\n",
      "12/12 - 0s - loss: 0.1140 - mean_absolute_error: 0.2665 - val_loss: 0.3907 - val_mean_absolute_error: 0.6100 - lr: 0.1000 - 479ms/epoch - 40ms/step\n",
      "Epoch 3/80\n",
      "12/12 - 0s - loss: 0.0515 - mean_absolute_error: 0.1892 - val_loss: 0.2233 - val_mean_absolute_error: 0.4546 - lr: 0.1000 - 458ms/epoch - 38ms/step\n",
      "Epoch 4/80\n",
      "12/12 - 0s - loss: 0.0389 - mean_absolute_error: 0.1665 - val_loss: 0.1818 - val_mean_absolute_error: 0.4072 - lr: 0.1000 - 414ms/epoch - 34ms/step\n",
      "Epoch 5/80\n",
      "12/12 - 0s - loss: 0.0373 - mean_absolute_error: 0.1655 - val_loss: 0.1989 - val_mean_absolute_error: 0.4274 - lr: 0.1000 - 467ms/epoch - 39ms/step\n",
      "Epoch 6/80\n",
      "12/12 - 0s - loss: 0.0407 - mean_absolute_error: 0.1684 - val_loss: 0.1593 - val_mean_absolute_error: 0.3790 - lr: 0.1000 - 431ms/epoch - 36ms/step\n",
      "Epoch 7/80\n",
      "12/12 - 1s - loss: 0.0382 - mean_absolute_error: 0.1636 - val_loss: 0.2452 - val_mean_absolute_error: 0.4778 - lr: 0.1000 - 526ms/epoch - 44ms/step\n",
      "Epoch 8/80\n",
      "12/12 - 1s - loss: 0.0414 - mean_absolute_error: 0.1622 - val_loss: 0.1779 - val_mean_absolute_error: 0.4024 - lr: 0.1000 - 525ms/epoch - 44ms/step\n",
      "Epoch 9/80\n",
      "12/12 - 0s - loss: 0.0463 - mean_absolute_error: 0.1819 - val_loss: 0.1211 - val_mean_absolute_error: 0.3257 - lr: 0.1000 - 464ms/epoch - 39ms/step\n",
      "Epoch 10/80\n",
      "12/12 - 1s - loss: 0.0419 - mean_absolute_error: 0.1663 - val_loss: 0.1945 - val_mean_absolute_error: 0.4222 - lr: 0.1000 - 635ms/epoch - 53ms/step\n",
      "Epoch 11/80\n",
      "12/12 - 0s - loss: 0.0395 - mean_absolute_error: 0.1645 - val_loss: 0.1021 - val_mean_absolute_error: 0.2959 - lr: 0.1000 - 498ms/epoch - 42ms/step\n",
      "Epoch 12/80\n",
      "12/12 - 0s - loss: 0.0379 - mean_absolute_error: 0.1636 - val_loss: 0.0895 - val_mean_absolute_error: 0.2747 - lr: 0.1000 - 487ms/epoch - 41ms/step\n",
      "Epoch 13/80\n",
      "12/12 - 0s - loss: 0.0407 - mean_absolute_error: 0.1666 - val_loss: 0.1713 - val_mean_absolute_error: 0.3943 - lr: 0.1000 - 490ms/epoch - 41ms/step\n",
      "Epoch 14/80\n",
      "12/12 - 0s - loss: 0.0408 - mean_absolute_error: 0.1688 - val_loss: 0.0695 - val_mean_absolute_error: 0.2374 - lr: 0.1000 - 398ms/epoch - 33ms/step\n",
      "Epoch 15/80\n",
      "12/12 - 0s - loss: 0.0407 - mean_absolute_error: 0.1723 - val_loss: 0.0798 - val_mean_absolute_error: 0.2572 - lr: 0.1000 - 466ms/epoch - 39ms/step\n",
      "Epoch 16/80\n",
      "12/12 - 0s - loss: 0.0421 - mean_absolute_error: 0.1744 - val_loss: 0.2100 - val_mean_absolute_error: 0.4400 - lr: 0.1000 - 457ms/epoch - 38ms/step\n",
      "Epoch 17/80\n",
      "12/12 - 0s - loss: 0.0447 - mean_absolute_error: 0.1750 - val_loss: 0.0432 - val_mean_absolute_error: 0.1799 - lr: 0.1000 - 420ms/epoch - 35ms/step\n",
      "Epoch 18/80\n",
      "12/12 - 0s - loss: 0.0639 - mean_absolute_error: 0.2037 - val_loss: 0.1109 - val_mean_absolute_error: 0.3100 - lr: 0.1000 - 423ms/epoch - 35ms/step\n",
      "Epoch 19/80\n",
      "12/12 - 0s - loss: 0.0718 - mean_absolute_error: 0.2184 - val_loss: 0.3809 - val_mean_absolute_error: 0.6021 - lr: 0.1000 - 486ms/epoch - 41ms/step\n",
      "Epoch 20/80\n",
      "12/12 - 1s - loss: 0.0639 - mean_absolute_error: 0.2026 - val_loss: 0.1557 - val_mean_absolute_error: 0.3743 - lr: 0.1000 - 554ms/epoch - 46ms/step\n",
      "Epoch 21/80\n",
      "12/12 - 1s - loss: 0.0510 - mean_absolute_error: 0.1889 - val_loss: 0.0843 - val_mean_absolute_error: 0.2654 - lr: 0.1000 - 530ms/epoch - 44ms/step\n",
      "Epoch 22/80\n",
      "12/12 - 0s - loss: 0.0382 - mean_absolute_error: 0.1596 - val_loss: 0.1967 - val_mean_absolute_error: 0.4248 - lr: 0.1000 - 452ms/epoch - 38ms/step\n",
      "Epoch 23/80\n",
      "12/12 - 1s - loss: 0.0371 - mean_absolute_error: 0.1635 - val_loss: 0.0970 - val_mean_absolute_error: 0.2874 - lr: 0.1000 - 503ms/epoch - 42ms/step\n",
      "Epoch 24/80\n",
      "12/12 - 0s - loss: 0.0396 - mean_absolute_error: 0.1692 - val_loss: 0.1029 - val_mean_absolute_error: 0.2971 - lr: 0.1000 - 485ms/epoch - 40ms/step\n",
      "Epoch 25/80\n",
      "12/12 - 0s - loss: 0.0441 - mean_absolute_error: 0.1685 - val_loss: 0.0941 - val_mean_absolute_error: 0.2825 - lr: 0.1000 - 420ms/epoch - 35ms/step\n",
      "Epoch 26/80\n",
      "12/12 - 0s - loss: 0.0495 - mean_absolute_error: 0.1846 - val_loss: 0.1886 - val_mean_absolute_error: 0.4154 - lr: 0.1000 - 402ms/epoch - 34ms/step\n",
      "Epoch 27/80\n",
      "12/12 - 0s - loss: 0.0481 - mean_absolute_error: 0.1753 - val_loss: 0.2656 - val_mean_absolute_error: 0.4985 - lr: 0.1000 - 410ms/epoch - 34ms/step\n",
      "Epoch 28/80\n",
      "12/12 - 0s - loss: 0.0453 - mean_absolute_error: 0.1743 - val_loss: 0.1353 - val_mean_absolute_error: 0.3465 - lr: 0.1000 - 421ms/epoch - 35ms/step\n",
      "Epoch 29/80\n",
      "12/12 - 0s - loss: 0.0374 - mean_absolute_error: 0.1602 - val_loss: 0.1624 - val_mean_absolute_error: 0.3829 - lr: 0.1000 - 409ms/epoch - 34ms/step\n",
      "Epoch 30/80\n",
      "12/12 - 0s - loss: 0.0395 - mean_absolute_error: 0.1670 - val_loss: 0.2482 - val_mean_absolute_error: 0.4810 - lr: 0.1000 - 408ms/epoch - 34ms/step\n",
      "Epoch 31/80\n",
      "12/12 - 0s - loss: 0.0438 - mean_absolute_error: 0.1674 - val_loss: 0.1107 - val_mean_absolute_error: 0.3097 - lr: 0.1000 - 381ms/epoch - 32ms/step\n",
      "Epoch 32/80\n",
      "12/12 - 0s - loss: 0.0404 - mean_absolute_error: 0.1631 - val_loss: 0.1583 - val_mean_absolute_error: 0.3777 - lr: 0.1000 - 386ms/epoch - 32ms/step\n",
      "Epoch 33/80\n",
      "12/12 - 0s - loss: 0.0376 - mean_absolute_error: 0.1599 - val_loss: 0.1475 - val_mean_absolute_error: 0.3633 - lr: 0.1000 - 374ms/epoch - 31ms/step\n",
      "Epoch 34/80\n",
      "12/12 - 0s - loss: 0.0363 - mean_absolute_error: 0.1623 - val_loss: 0.1279 - val_mean_absolute_error: 0.3357 - lr: 0.1000 - 381ms/epoch - 32ms/step\n",
      "Epoch 35/80\n",
      "12/12 - 0s - loss: 0.0364 - mean_absolute_error: 0.1589 - val_loss: 0.2068 - val_mean_absolute_error: 0.4363 - lr: 0.1000 - 399ms/epoch - 33ms/step\n",
      "Epoch 36/80\n",
      "12/12 - 0s - loss: 0.0384 - mean_absolute_error: 0.1668 - val_loss: 0.0959 - val_mean_absolute_error: 0.2856 - lr: 0.1000 - 400ms/epoch - 33ms/step\n",
      "Epoch 37/80\n",
      "12/12 - 0s - loss: 0.0405 - mean_absolute_error: 0.1710 - val_loss: 0.0867 - val_mean_absolute_error: 0.2697 - lr: 0.1000 - 430ms/epoch - 36ms/step\n",
      "4/4 [==============================] - 0s 16ms/step\n",
      "Fold 2 , val_loss is : 0.09, MAE scaled is : 0.27, MAE original is : 23.43\n"
     ]
    }
   ],
   "source": [
    "time_series_split_folds = TimeSeriesSplit(n_splits=N_SPLITS)\n",
    "performance = []\n",
    "for fold ,(training_idx, validation_idx) in enumerate(time_series_split_folds.split(X,y)):\n",
    "    transformer_model = transformer_architecture(INPUT_SHAPE,LR,SEQ_LEN,D_MODEL,NUM_HEADS,KEY_DIM)\n",
    "\n",
    "    X_train_cv = tf.convert_to_tensor(X[training_idx], dtype=tf.float32)\n",
    "    X_val_cv = tf.convert_to_tensor(X[validation_idx], dtype=tf.float32)\n",
    "    y_train_cv = tf.convert_to_tensor(y_scaled[training_idx], dtype=tf.float32)\n",
    "    y_val_cv = tf.convert_to_tensor(y_scaled[validation_idx], dtype=tf.float32)\n",
    "    \n",
    "    train_start = perf_counter()\n",
    "    history = transformer_model.fit(X_train_cv,y_train_cv,epochs=EPOCHS,validation_data=(X_val_cv,y_val_cv),callbacks=CALLBACK,verbose=2)\n",
    "    train_end = perf_counter()\n",
    "    \n",
    "    val_loss, val_mae = transformer_model.evaluate(X_val_cv, y_val_cv,verbose=0)\n",
    "    \n",
    "    y_val_preds = transformer_model.predict(X_val_cv)\n",
    "    y_val_preds = y_val_preds[:, -1, :]  # The last predict gives 3 predictions for each input , thus we only take the last one with -1\n",
    "    \n",
    "    # Reshape predictions\n",
    "    y_val_preds_reshaped = y_val_preds.reshape(-1, 1) # from (dim1,1) to (dim1,)\n",
    "\n",
    "    # Apply inverse transform\n",
    "    y_val_preds_original = scaler.inverse_transform(y_val_preds_reshaped).flatten() # to get the original co2 values not between 0-1\n",
    "\n",
    "    # Reshape validation data\n",
    "    y_val_reshaped = y_val_cv.numpy().reshape(-1, 1) # from (dim1,1) to (dim1,)\n",
    "\n",
    "    # Apply inverse transform\n",
    "    y_val_original = scaler.inverse_transform(y_val_reshaped).flatten() # to get the original co2 values not between 0-1\n",
    "    \n",
    "    # Calculating the metrics :\n",
    "    y_mean = np.mean(y_val_original)\n",
    "    mae_original = np.mean(np.abs(y_val_preds_original - y_val_original))\n",
    "    mape_calculated = np.mean(np.abs((y_val_preds_original - y_val_original) / y_val_original)) # mape = 1/n * sum( abs(y_real - y_predicted) )\n",
    "    \n",
    "    sce = np.sum((y_val_preds_original - y_mean) ** 2)\n",
    "    sst = np.sum((y_val_original - y_mean) ** 2)\n",
    "    r2_calculated = sce / sst # r2 = SCE / SST\n",
    "    \n",
    "    performance.append({\n",
    "    \"fold\": fold,\n",
    "    \"loss\": f'{history.history[\"loss\"]}',\n",
    "    \"mae\": f'{history.history[\"mean_absolute_error\"]}',\n",
    "    \"val_loss\": f'{history.history[\"val_loss\"]}',\n",
    "    \"val_mae_scaled\": f'{history.history[\"val_mean_absolute_error\"]}',\n",
    "    \"val_mae_original\": f'{mae_original:.4f}',\n",
    "    \"r2_calculated\": f'{r2_calculated:.4f}',\n",
    "    \"training_time\": f'{train_end-train_start}'\n",
    "    })    \n",
    "    print(f'Fold {fold} , val_loss is : {val_loss:.2f}, MAE scaled is : {val_mae:.2f}, MAE original is : {mae_original:.2f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77557b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame(performance)\n",
    "performance.to_csv('transformer_performance.csv')\n",
    "print(performance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9f0ec4-552d-4614-88a1-acd97f035649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input,Dense,LSTM,Dropout\n",
    "from tensorflow.keras.losses import MeanSquaredError,MeanAbsoluteError\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1b071f",
   "metadata": {},
   "source": [
    "## you could delete this line here \n",
    "- i needed it cause im using wsl for tensorflow, but in normal windows, its possible to remove it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c423fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/tf-acno-projects/Project-Data-Mining')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25d3382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_y_forecasting_splits(Datafile,time_steps):\n",
    "    X,y = list(),list()\n",
    "    for start in range(len(Datafile)):\n",
    "        end = start+time_steps \n",
    "        if end>len(Datafile)-1:\n",
    "            break\n",
    "        X.append(Datafile.iloc[start:end].values)\n",
    "        y.append(Datafile.iloc[end][\"CO2 Emission\"])\n",
    "    return np.array(X),np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8d14c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def months_converter(DataFile):\n",
    "    unique_months = DataFile['Month'].unique()\n",
    "    months_dict = {\n",
    "        month:idx+1 for idx,month in enumerate(unique_months)\n",
    "    }\n",
    "    DataFile['Month'] = DataFile['Month'].map(months_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc50550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_architecture(INPUT_SHAPE,LR):\n",
    "    input_layer = Input(shape=INPUT_SHAPE)\n",
    "    hidden_layer = LSTM(32,activation='relu')(input_layer)\n",
    "    dropout_layer = Dropout(0.4)(hidden_layer)\n",
    "    output_layer = Dense(1,activation='linear')(dropout_layer)\n",
    "\n",
    "    lstm_model = Model(input_layer,output_layer)\n",
    "    lstm_model.summary()\n",
    "    lstm_model.compile(optimizer=Adam(learning_rate=LR),loss=MeanSquaredError(),metrics=[MeanAbsoluteError()])\n",
    "    return lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39daf82a-f82a-45c0-a62c-e820fde8b442",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFile = pd.read_csv(\"Emission.csv\")\n",
    "\n",
    "DataFile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3c1467-6b63-40db-ad7c-9c75f8297757",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DataFile.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17fdbe7-0839-4826-8fbb-334cb64366b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DataFile.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269d0dc9-ce40-4e53-b339-6b6cf108aac8",
   "metadata": {},
   "source": [
    "Alright, there are no null values and no duplicates but there is something wrong with the \"Year-Month\" column, it's better to split it into two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf323fe-847b-4303-926a-454baf775a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFile[['Year', 'Month']] = DataFile['Year-Month'].str.split('-', expand=True)\n",
    "\n",
    "DataFile.drop(columns=['Year-Month'], inplace=True)\n",
    "\n",
    "months_converter(DataFile)\n",
    "\n",
    "for col in DataFile.columns:\n",
    "    DataFile[col] = pd.to_numeric(DataFile[col],errors='coerce')\n",
    "print(DataFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c41f3b-0ffb-4a21-ba5b-8f894b0ed742",
   "metadata": {},
   "source": [
    "Now we need to perform visual analysis on our dataset, but first we need to create a csv of our new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3690acd5-0369-49cf-b1ba-1fef274c93c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFile.to_csv(\"New Emission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe38774-4f7d-494c-bd52-8fb179be787e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFile = pd.read_csv(\"New Emission.csv\")\n",
    "\n",
    "DataFile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a20a4d2-efbc-413a-a2b9-bdadb07d004c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DataFile.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9019b6-bab1-49cd-94a6-8a9a7abbb43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(DataFile[\"Year\"], DataFile[\"CO2 Emission\"], marker=\"o\", linestyle=\"-\", color=\"b\")\n",
    "\n",
    "# Labels and Title\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"CO2 Emission (ppm)\")\n",
    "plt.title(\"CO2 Emission Over the Years\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee544538-e546-4aae-97a5-c26c8014acf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=DataFile[\"Month\"], y=DataFile[\"CO2 Emission\"], palette=\"coolwarm\")\n",
    "\n",
    "# Labels and Title\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"CO2 Emission (ppm)\")\n",
    "plt.title(\"CO2 Emission by Month\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48417bf-3df5-41db-85cd-94d73c8efc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "sns.barplot(x=DataFile[\"Year\"], y=DataFile[\"CO2 Emission\"], palette=\"coolwarm\")\n",
    "\n",
    "# Labels and Title\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"CO2 Emission (ppm)\")\n",
    "plt.title(\"CO2 Emission by Year\")\n",
    "\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e06e71d-27d9-4ad8-87a8-915ffe21ac25",
   "metadata": {},
   "source": [
    "It's kind of a complex figure so we will group the years into ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809b68c8-bfbe-494a-92a0-f9ff70464ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_year = DataFile[\"Year\"].min()\n",
    "max_year = DataFile[\"Year\"].max()\n",
    "\n",
    "print(min_year)\n",
    "print(max_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57cc83e-dbd7-4483-aa0b-1370dc69ec7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [1970, 1975, 1980, 1985, 1990, 1995, 2000, 2005, 2010, 2015]\n",
    "\n",
    "labels = [\"1971-1975\", \"1976-1980\", \"1981-1985\", \"1986-1990\", \"1991-1995\", \"1996-2000\", \"2001-2005\", \"2006-2010\", \"2011-2015\"]\n",
    "\n",
    "DataFile[\"Year Range\"] = pd.cut(DataFile[\"Year\"], bins=bins, labels=labels, right=True)\n",
    "print(DataFile[[\"Year\", \"Year Range\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2061a7-8d46-447f-b5f4-33e3c0d82d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2077229-454a-42e6-a1f9-7d5fbbec345c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))  # Increase width\n",
    "sns.barplot(x=DataFile[\"Year Range\"], y=DataFile[\"CO2 Emission\"], palette=\"coolwarm\")\n",
    "\n",
    "plt.xlabel(\"Year Range\")\n",
    "plt.ylabel(\"CO2 Emission (ppm)\")\n",
    "plt.title(\"CO2 Emission by Year\")\n",
    "\n",
    "plt.xticks(rotation=45, ha=\"right\")  # Rotate labels for better spacing\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3900c72-e2b4-4024-b223-e6ee6e974516",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFile.drop(columns=['Year Range'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e949f7b2-92cf-4443-baf0-63f299b8df48",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFile.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daea0655",
   "metadata": {},
   "source": [
    "### LSTM AND TRANSFORMERS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87e1dd3",
   "metadata": {},
   "source": [
    "We have 486 rows so :\n",
    "- train 80% = int(len(DataFile)*0.8)+1 => 389\n",
    "- test 10% =  int(len(DataFile)*0.1) => 48\n",
    "- validation 10% = int(len(DataFile)*0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2fc460",
   "metadata": {},
   "source": [
    "#### first we convert strings into numerical values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f632a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step = 3\n",
    "X,y = X_y_forecasting_splits(DataFile,time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c24b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (3,3)\n",
    "LR = 0.01\n",
    "EPOCHS = 100\n",
    "N_SPLITS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a369826a-921f-4e3a-821f-9d51f3569422",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(DataFile)*0.8) + 1 \n",
    "test_val_size = int(len(DataFile)*0.1)\n",
    "\n",
    "X_train,y_train = X[:train_size],y[:train_size]\n",
    "X_test,y_test= X[train_size:train_size+test_val_size],y[train_size:train_size+test_val_size]\n",
    "X_val,y_val = X[train_size+test_val_size:],y[train_size+test_val_size:]\n",
    "\n",
    "print(f'train size is : {train_size}, test val size is : {test_val_size}')\n",
    "print(f'train : {X_train.shape} , {y_train.shape}')\n",
    "print(f'test : {X_test.shape} , {y_test.shape}')\n",
    "print(f'val : {X_val.shape} , {y_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53b7ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = lstm_architecture(INPUT_SHAPE,LR)\n",
    "time_series_split_folds = TimeSeriesSplit(n_splits=N_SPLITS)\n",
    "performance = []\n",
    "for fold ,(training_idx, validation_idx) in enumerate(time_series_split_folds.split(X,y)):\n",
    "    \n",
    "    X_train_cv = tf.convert_to_tensor(X[training_idx], dtype=tf.float32)\n",
    "    X_val_cv = tf.convert_to_tensor(X[validation_idx], dtype=tf.float32)\n",
    "    y_train_cv = tf.convert_to_tensor(y[training_idx], dtype=tf.float32)\n",
    "    y_val_cv = tf.convert_to_tensor(y[validation_idx], dtype=tf.float32)\n",
    "    \n",
    "    lstm_model.fit(X_train,y_train,epochs=EPOCHS,validation_data=(X_val,y_val),verbose=1)\n",
    "    val_loss, val_mae = lstm_model.evaluate(X_val, y_val,verbose=0)\n",
    "    \n",
    "    performance.append({\n",
    "    \"fold\": fold,\n",
    "    \"val_loss\": val_loss,\n",
    "    \"val_accuracy\": val_mae,\n",
    "    })    \n",
    "    print(f'Fold {fold} , val_loss is : {val_loss:.2f} , MAE is : {val_mae:.2f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c7e6bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

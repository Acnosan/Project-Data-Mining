{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5c9f0ec4-552d-4614-88a1-acd97f035649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input,Dense,LSTM,Dropout\n",
    "from tensorflow.keras.losses import MeanSquaredError,MeanAbsoluteError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1b071f",
   "metadata": {},
   "source": [
    "## you could delete this line here (os one)\n",
    "- i needed it cause im using wsl for tensorflow, but in normal windows, its possible to remove it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1c423fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/tf-acno-projects/Project-Data-Mining')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d25d3382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_y_forecasting_splits(Datafile,time_steps):\n",
    "    X,y = list(),list()\n",
    "    for start in range(len(Datafile)):\n",
    "        end = start+time_steps \n",
    "        if end>len(Datafile)-1:\n",
    "            break\n",
    "        X.append(Datafile.iloc[start:end].values)\n",
    "        y.append(Datafile.iloc[end][\"CO2 Emission\"])\n",
    "    return np.array(X),np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fe8d14c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def months_converter(DataFile):\n",
    "    unique_months = DataFile['Month'].unique()\n",
    "    months_dict = {\n",
    "        month:idx+1 for idx,month in enumerate(unique_months)\n",
    "    }\n",
    "    DataFile['Month'] = DataFile['Month'].map(months_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cfc50550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_architecture(INPUT_SHAPE,LR):\n",
    "    input_layer = Input(shape=INPUT_SHAPE)\n",
    "    hidden_layer = LSTM(64)(input_layer)\n",
    "    hidden_layer = Dense(32,activation='relu')(hidden_layer)\n",
    "    hidden_layer = Dense(16,activation='relu')(hidden_layer)\n",
    "    output_layer = Dense(1,activation='linear')(hidden_layer)\n",
    "\n",
    "    lstm_model = Model(input_layer,output_layer)\n",
    "    #lstm_model.summary()\n",
    "    lstm_model.compile(optimizer=Adam(learning_rate=LR),loss=MeanSquaredError(),metrics=[MeanAbsoluteError()])\n",
    "    return lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "39daf82a-f82a-45c0-a62c-e820fde8b442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Year-Month",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "CO2 Emission",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "ac18b735-dcd0-416c-8984-05ad7b022915",
       "rows": [
        [
         "0",
         "1973-Jan",
         "106.363"
        ],
        [
         "1",
         "1973-Feb",
         "101.76"
        ],
        [
         "2",
         "1973-Mar",
         "110.553"
        ],
        [
         "3",
         "1973-Apr",
         "104.734"
        ],
        [
         "4",
         "1973-May",
         "114.897"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year-Month</th>\n",
       "      <th>CO2 Emission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1973-Jan</td>\n",
       "      <td>106.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1973-Feb</td>\n",
       "      <td>101.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1973-Mar</td>\n",
       "      <td>110.553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1973-Apr</td>\n",
       "      <td>104.734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1973-May</td>\n",
       "      <td>114.897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Year-Month  CO2 Emission\n",
       "0   1973-Jan       106.363\n",
       "1   1973-Feb       101.760\n",
       "2   1973-Mar       110.553\n",
       "3   1973-Apr       104.734\n",
       "4   1973-May       114.897"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFile = pd.read_csv(\"Emission.csv\")\n",
    "DataFile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7f3c1467-6b63-40db-ad7c-9c75f8297757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year-Month      0\n",
      "CO2 Emission    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(DataFile.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b17fdbe7-0839-4826-8fbb-334cb64366b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(DataFile.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269d0dc9-ce40-4e53-b339-6b6cf108aac8",
   "metadata": {},
   "source": [
    "Alright, there are no null values and no duplicates but there is something wrong with the \"Year-Month\" column, it's better to split it into two and convert them to numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fdf323fe-847b-4303-926a-454baf775a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     CO2 Emission  Year  Month\n",
      "0         106.363  1973      1\n",
      "1         101.760  1973      2\n",
      "2         110.553  1973      3\n",
      "3         104.734  1973      4\n",
      "4         114.897  1973      5\n",
      "..            ...   ...    ...\n",
      "481       134.243  2013      2\n",
      "482       153.078  2013      3\n",
      "483       149.442  2013      4\n",
      "484       156.356  2013      5\n",
      "485       152.814  2013      6\n",
      "\n",
      "[486 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "DataFile[['Year', 'Month']] = DataFile['Year-Month'].str.split('-', expand=True)\n",
    "\n",
    "DataFile.drop(columns=['Year-Month'], inplace=True)\n",
    "\n",
    "months_converter(DataFile)\n",
    "\n",
    "for col in DataFile.columns:\n",
    "    DataFile[col] = pd.to_numeric(DataFile[col],errors='coerce')\n",
    "print(DataFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2830b789",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFile['CO2 Emission'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b612194",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFile['CO2 Emission'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6903bc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFile['CO2 Emission'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61ddcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFile['CO2 Emission'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26029c1f",
   "metadata": {},
   "source": [
    "this is a note that we should scale the data later on for our models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c41f3b-0ffb-4a21-ba5b-8f894b0ed742",
   "metadata": {},
   "source": [
    "Now we need to perform visual analysis on our dataset, but first we need to create a csv of our new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3690acd5-0369-49cf-b1ba-1fef274c93c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFile.to_csv(\"New Emission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe38774-4f7d-494c-bd52-8fb179be787e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFile = pd.read_csv(\"New Emission.csv\")\n",
    "\n",
    "DataFile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a20a4d2-efbc-413a-a2b9-bdadb07d004c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DataFile.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9019b6-bab1-49cd-94a6-8a9a7abbb43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(DataFile[\"Year\"], DataFile[\"CO2 Emission\"], marker=\"o\", linestyle=\"-\", color=\"b\")\n",
    "\n",
    "# Labels and Title\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"CO2 Emission (ppm)\")\n",
    "plt.title(\"CO2 Emission Over the Years\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee544538-e546-4aae-97a5-c26c8014acf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=DataFile[\"Month\"], y=DataFile[\"CO2 Emission\"], palette=\"coolwarm\")\n",
    "\n",
    "# Labels and Title\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"CO2 Emission (ppm)\")\n",
    "plt.title(\"CO2 Emission by Month\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48417bf-3df5-41db-85cd-94d73c8efc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "sns.barplot(x=DataFile[\"Year\"], y=DataFile[\"CO2 Emission\"], palette=\"coolwarm\")\n",
    "\n",
    "# Labels and Title\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"CO2 Emission (ppm)\")\n",
    "plt.title(\"CO2 Emission by Year\")\n",
    "\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e06e71d-27d9-4ad8-87a8-915ffe21ac25",
   "metadata": {},
   "source": [
    "It's kind of a complex figure so we will group the years into ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809b68c8-bfbe-494a-92a0-f9ff70464ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_year = DataFile[\"Year\"].min()\n",
    "max_year = DataFile[\"Year\"].max()\n",
    "\n",
    "print(min_year)\n",
    "print(max_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57cc83e-dbd7-4483-aa0b-1370dc69ec7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [1970, 1975, 1980, 1985, 1990, 1995, 2000, 2005, 2010, 2015]\n",
    "\n",
    "labels = [\"1971-1975\", \"1976-1980\", \"1981-1985\", \"1986-1990\", \"1991-1995\", \"1996-2000\", \"2001-2005\", \"2006-2010\", \"2011-2015\"]\n",
    "\n",
    "DataFile[\"Year Range\"] = pd.cut(DataFile[\"Year\"], bins=bins, labels=labels, right=True)\n",
    "print(DataFile[[\"Year\", \"Year Range\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2061a7-8d46-447f-b5f4-33e3c0d82d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2077229-454a-42e6-a1f9-7d5fbbec345c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))  # Increase width\n",
    "sns.barplot(x=DataFile[\"Year Range\"], y=DataFile[\"CO2 Emission\"], palette=\"coolwarm\")\n",
    "\n",
    "plt.xlabel(\"Year Range\")\n",
    "plt.ylabel(\"CO2 Emission (ppm)\")\n",
    "plt.title(\"CO2 Emission by Year\")\n",
    "\n",
    "plt.xticks(rotation=45, ha=\"right\")  # Rotate labels for better spacing\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3900c72-e2b4-4024-b223-e6ee6e974516",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFile.drop(columns=['Year Range'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e949f7b2-92cf-4443-baf0-63f299b8df48",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFile.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daea0655",
   "metadata": {},
   "source": [
    "## LSTM AND TRANSFORMERS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87e1dd3",
   "metadata": {},
   "source": [
    "We have 486 rows so :\n",
    "- train 80% = int(len(DataFile)*0.8)+1 => 389\n",
    "- test 10% =  int(len(DataFile)*0.1) => 48\n",
    "- validation 10% = int(len(DataFile)*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "43f632a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step = 3\n",
    "X,y = X_y_forecasting_splits(DataFile,time_step)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "y_scaled = scaler.fit_transform(y.reshape(-1,1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "17c24b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (time_step,3)\n",
    "LR = 0.1\n",
    "EPOCHS = 80\n",
    "N_SPLITS = 3\n",
    "CALLBACK = [\n",
    "    ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,\n",
    "    patience=20,\n",
    "    min_delta=0.0005,\n",
    "    min_lr=1e-6,\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=20,\n",
    "    min_delta=0.0001,\n",
    "    )]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a369826a-921f-4e3a-821f-9d51f3569422",
   "metadata": {},
   "source": [
    "train_size = int(len(DataFile)*0.8) + 1 \n",
    "test_val_size = int(len(DataFile)*0.1)\n",
    "\n",
    "X_train,y_train = X[:train_size],y[:train_size]\n",
    "X_test,y_test= X[train_size:train_size+test_val_size],y[train_size:train_size+test_val_size]\n",
    "X_val,y_val = X[train_size+test_val_size:],y[train_size+test_val_size:]\n",
    "\n",
    "print(f'train size is : {train_size}, test val size is : {test_val_size}')\n",
    "print(f'train : {X_train.shape} , {y_train.shape}')\n",
    "print(f'test : {X_test.shape} , {y_test.shape}')\n",
    "print(f'val : {X_val.shape} , {y_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54fe593",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "b53b7ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "4/4 [==============================] - 3s 189ms/step - loss: 1.0539 - mean_absolute_error: 0.7281 - val_loss: 0.0252 - val_mean_absolute_error: 0.1404 - lr: 0.1000\n",
      "Epoch 2/80\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0111 - mean_absolute_error: 0.0843 - val_loss: 0.0098 - val_mean_absolute_error: 0.0773 - lr: 0.1000\n",
      "Epoch 3/80\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.0176 - mean_absolute_error: 0.1036 - val_loss: 0.0397 - val_mean_absolute_error: 0.1826 - lr: 0.1000\n",
      "Epoch 4/80\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0060 - mean_absolute_error: 0.0612 - val_loss: 0.0305 - val_mean_absolute_error: 0.1563 - lr: 0.1000\n",
      "Epoch 5/80\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0058 - mean_absolute_error: 0.0597 - val_loss: 0.0251 - val_mean_absolute_error: 0.1401 - lr: 0.1000\n",
      "Epoch 6/80\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.0065 - mean_absolute_error: 0.0628 - val_loss: 0.0232 - val_mean_absolute_error: 0.1340 - lr: 0.1000\n",
      "Epoch 7/80\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.0066 - mean_absolute_error: 0.0631 - val_loss: 0.0244 - val_mean_absolute_error: 0.1379 - lr: 0.1000\n",
      "Epoch 8/80\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.0062 - mean_absolute_error: 0.0614 - val_loss: 0.0274 - val_mean_absolute_error: 0.1470 - lr: 0.1000\n",
      "Epoch 9/80\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0060 - mean_absolute_error: 0.0604 - val_loss: 0.0312 - val_mean_absolute_error: 0.1584 - lr: 0.1000\n",
      "Epoch 10/80\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0059 - mean_absolute_error: 0.0597 - val_loss: 0.0337 - val_mean_absolute_error: 0.1656 - lr: 0.1000\n",
      "Epoch 11/80\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0060 - mean_absolute_error: 0.0600 - val_loss: 0.0337 - val_mean_absolute_error: 0.1658 - lr: 0.1000\n",
      "Epoch 12/80\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0060 - mean_absolute_error: 0.0599 - val_loss: 0.0323 - val_mean_absolute_error: 0.1617 - lr: 0.1000\n",
      "Epoch 13/80\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0059 - mean_absolute_error: 0.0607 - val_loss: 0.0305 - val_mean_absolute_error: 0.1561 - lr: 0.1000\n",
      "Epoch 14/80\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0059 - mean_absolute_error: 0.0599 - val_loss: 0.0292 - val_mean_absolute_error: 0.1523 - lr: 0.1000\n",
      "Epoch 15/80\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0059 - mean_absolute_error: 0.0598 - val_loss: 0.0297 - val_mean_absolute_error: 0.1537 - lr: 0.1000\n",
      "Epoch 16/80\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0059 - mean_absolute_error: 0.0599 - val_loss: 0.0299 - val_mean_absolute_error: 0.1543 - lr: 0.1000\n",
      "Epoch 17/80\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0059 - mean_absolute_error: 0.0599 - val_loss: 0.0308 - val_mean_absolute_error: 0.1570 - lr: 0.1000\n",
      "Epoch 18/80\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0059 - mean_absolute_error: 0.0599 - val_loss: 0.0307 - val_mean_absolute_error: 0.1569 - lr: 0.1000\n",
      "Epoch 19/80\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0059 - mean_absolute_error: 0.0594 - val_loss: 0.0312 - val_mean_absolute_error: 0.1585 - lr: 0.1000\n",
      "Epoch 20/80\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0059 - mean_absolute_error: 0.0598 - val_loss: 0.0312 - val_mean_absolute_error: 0.1585 - lr: 0.1000\n",
      "Epoch 21/80\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0059 - mean_absolute_error: 0.0602 - val_loss: 0.0299 - val_mean_absolute_error: 0.1544 - lr: 0.1000\n",
      "Epoch 22/80\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0059 - mean_absolute_error: 0.0601 - val_loss: 0.0297 - val_mean_absolute_error: 0.1538 - lr: 0.1000\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "Fold 0 , val_loss is : 0.03, MAE scaled is : 0.15, MAE original is : 12.74\n",
      "Epoch 1/80\n",
      "8/8 [==============================] - 5s 93ms/step - loss: 0.4900 - mean_absolute_error: 0.5547 - val_loss: 0.0375 - val_mean_absolute_error: 0.1713 - lr: 0.1000\n",
      "Epoch 2/80\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0266 - mean_absolute_error: 0.1297 - val_loss: 0.0122 - val_mean_absolute_error: 0.0945 - lr: 0.1000\n",
      "Epoch 3/80\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0349 - mean_absolute_error: 0.1397 - val_loss: 0.1158 - val_mean_absolute_error: 0.3289 - lr: 0.1000\n",
      "Epoch 4/80\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0156 - mean_absolute_error: 0.1058 - val_loss: 0.1262 - val_mean_absolute_error: 0.3446 - lr: 0.1000\n",
      "Epoch 5/80\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0138 - mean_absolute_error: 0.0951 - val_loss: 0.1137 - val_mean_absolute_error: 0.3255 - lr: 0.1000\n",
      "Epoch 6/80\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0137 - mean_absolute_error: 0.0990 - val_loss: 0.1230 - val_mean_absolute_error: 0.3398 - lr: 0.1000\n",
      "Epoch 7/80\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0132 - mean_absolute_error: 0.0939 - val_loss: 0.1140 - val_mean_absolute_error: 0.3260 - lr: 0.1000\n",
      "Epoch 8/80\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0130 - mean_absolute_error: 0.0959 - val_loss: 0.1213 - val_mean_absolute_error: 0.3373 - lr: 0.1000\n",
      "Epoch 9/80\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0129 - mean_absolute_error: 0.0941 - val_loss: 0.1177 - val_mean_absolute_error: 0.3317 - lr: 0.1000\n",
      "Epoch 10/80\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0130 - mean_absolute_error: 0.0941 - val_loss: 0.1170 - val_mean_absolute_error: 0.3307 - lr: 0.1000\n",
      "Epoch 11/80\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0132 - mean_absolute_error: 0.0964 - val_loss: 0.1248 - val_mean_absolute_error: 0.3425 - lr: 0.1000\n",
      "Epoch 12/80\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0131 - mean_absolute_error: 0.0934 - val_loss: 0.1165 - val_mean_absolute_error: 0.3298 - lr: 0.1000\n",
      "Epoch 13/80\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0129 - mean_absolute_error: 0.0949 - val_loss: 0.1161 - val_mean_absolute_error: 0.3292 - lr: 0.1000\n",
      "Epoch 14/80\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0130 - mean_absolute_error: 0.0947 - val_loss: 0.1181 - val_mean_absolute_error: 0.3324 - lr: 0.1000\n",
      "Epoch 15/80\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0130 - mean_absolute_error: 0.0949 - val_loss: 0.1163 - val_mean_absolute_error: 0.3296 - lr: 0.1000\n",
      "Epoch 16/80\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0131 - mean_absolute_error: 0.0945 - val_loss: 0.1262 - val_mean_absolute_error: 0.3446 - lr: 0.1000\n",
      "Epoch 17/80\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0130 - mean_absolute_error: 0.0946 - val_loss: 0.1102 - val_mean_absolute_error: 0.3200 - lr: 0.1000\n",
      "Epoch 18/80\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0130 - mean_absolute_error: 0.0952 - val_loss: 0.1247 - val_mean_absolute_error: 0.3423 - lr: 0.1000\n",
      "Epoch 19/80\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0128 - mean_absolute_error: 0.0940 - val_loss: 0.1095 - val_mean_absolute_error: 0.3188 - lr: 0.1000\n",
      "Epoch 20/80\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0131 - mean_absolute_error: 0.0973 - val_loss: 0.1233 - val_mean_absolute_error: 0.3402 - lr: 0.1000\n",
      "Epoch 21/80\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0130 - mean_absolute_error: 0.0941 - val_loss: 0.1180 - val_mean_absolute_error: 0.3323 - lr: 0.1000\n",
      "Epoch 22/80\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0129 - mean_absolute_error: 0.0942 - val_loss: 0.1198 - val_mean_absolute_error: 0.3350 - lr: 0.1000\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "Fold 1 , val_loss is : 0.12, MAE scaled is : 0.33, MAE original is : 27.95\n",
      "Epoch 1/80\n",
      "12/12 [==============================] - 3s 63ms/step - loss: 0.4767 - mean_absolute_error: 0.4761 - val_loss: 0.3328 - val_mean_absolute_error: 0.5612 - lr: 0.1000\n",
      "Epoch 2/80\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0458 - mean_absolute_error: 0.1738 - val_loss: 0.1871 - val_mean_absolute_error: 0.4136 - lr: 0.1000\n",
      "Epoch 3/80\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0400 - mean_absolute_error: 0.1690 - val_loss: 0.1794 - val_mean_absolute_error: 0.4042 - lr: 0.1000\n",
      "Epoch 4/80\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0399 - mean_absolute_error: 0.1671 - val_loss: 0.2058 - val_mean_absolute_error: 0.4353 - lr: 0.1000\n",
      "Epoch 5/80\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0383 - mean_absolute_error: 0.1616 - val_loss: 0.1268 - val_mean_absolute_error: 0.3342 - lr: 0.1000\n",
      "Epoch 6/80\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0359 - mean_absolute_error: 0.1590 - val_loss: 0.1541 - val_mean_absolute_error: 0.3721 - lr: 0.1000\n",
      "Epoch 7/80\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0363 - mean_absolute_error: 0.1577 - val_loss: 0.1265 - val_mean_absolute_error: 0.3337 - lr: 0.1000\n",
      "Epoch 8/80\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0362 - mean_absolute_error: 0.1605 - val_loss: 0.1644 - val_mean_absolute_error: 0.3855 - lr: 0.1000\n",
      "Epoch 9/80\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0371 - mean_absolute_error: 0.1612 - val_loss: 0.1240 - val_mean_absolute_error: 0.3301 - lr: 0.1000\n",
      "Epoch 10/80\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0362 - mean_absolute_error: 0.1643 - val_loss: 0.1464 - val_mean_absolute_error: 0.3619 - lr: 0.1000\n",
      "Epoch 11/80\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0360 - mean_absolute_error: 0.1606 - val_loss: 0.1316 - val_mean_absolute_error: 0.3412 - lr: 0.1000\n",
      "Epoch 12/80\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0369 - mean_absolute_error: 0.1610 - val_loss: 0.1567 - val_mean_absolute_error: 0.3756 - lr: 0.1000\n",
      "Epoch 13/80\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0366 - mean_absolute_error: 0.1610 - val_loss: 0.1406 - val_mean_absolute_error: 0.3538 - lr: 0.1000\n",
      "Epoch 14/80\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0364 - mean_absolute_error: 0.1617 - val_loss: 0.1403 - val_mean_absolute_error: 0.3534 - lr: 0.1000\n",
      "Epoch 15/80\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0361 - mean_absolute_error: 0.1580 - val_loss: 0.1392 - val_mean_absolute_error: 0.3519 - lr: 0.1000\n",
      "Epoch 16/80\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0364 - mean_absolute_error: 0.1637 - val_loss: 0.1488 - val_mean_absolute_error: 0.3651 - lr: 0.1000\n",
      "Epoch 17/80\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0364 - mean_absolute_error: 0.1595 - val_loss: 0.1423 - val_mean_absolute_error: 0.3563 - lr: 0.1000\n",
      "Epoch 18/80\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0363 - mean_absolute_error: 0.1617 - val_loss: 0.1420 - val_mean_absolute_error: 0.3558 - lr: 0.1000\n",
      "Epoch 19/80\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0382 - mean_absolute_error: 0.1657 - val_loss: 0.1837 - val_mean_absolute_error: 0.4095 - lr: 0.1000\n",
      "Epoch 20/80\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0371 - mean_absolute_error: 0.1603 - val_loss: 0.1255 - val_mean_absolute_error: 0.3323 - lr: 0.1000\n",
      "Epoch 21/80\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0365 - mean_absolute_error: 0.1621 - val_loss: 0.1411 - val_mean_absolute_error: 0.3546 - lr: 0.1000\n",
      "Epoch 22/80\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0361 - mean_absolute_error: 0.1616 - val_loss: 0.1335 - val_mean_absolute_error: 0.3439 - lr: 0.1000\n",
      "Epoch 23/80\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0368 - mean_absolute_error: 0.1590 - val_loss: 0.1491 - val_mean_absolute_error: 0.3656 - lr: 0.1000\n",
      "Epoch 24/80\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0363 - mean_absolute_error: 0.1596 - val_loss: 0.1427 - val_mean_absolute_error: 0.3567 - lr: 0.1000\n",
      "Epoch 25/80\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0362 - mean_absolute_error: 0.1594 - val_loss: 0.1271 - val_mean_absolute_error: 0.3346 - lr: 0.1000\n",
      "Epoch 26/80\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0366 - mean_absolute_error: 0.1638 - val_loss: 0.1643 - val_mean_absolute_error: 0.3854 - lr: 0.1000\n",
      "Epoch 27/80\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0366 - mean_absolute_error: 0.1611 - val_loss: 0.1371 - val_mean_absolute_error: 0.3489 - lr: 0.1000\n",
      "Epoch 28/80\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0369 - mean_absolute_error: 0.1617 - val_loss: 0.1296 - val_mean_absolute_error: 0.3382 - lr: 0.1000\n",
      "Epoch 29/80\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0363 - mean_absolute_error: 0.1628 - val_loss: 0.1408 - val_mean_absolute_error: 0.3541 - lr: 0.1000\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "Fold 2 , val_loss is : 0.14, MAE scaled is : 0.35, MAE original is : 30.61\n"
     ]
    }
   ],
   "source": [
    "time_series_split_folds = TimeSeriesSplit(n_splits=N_SPLITS)\n",
    "performance = []\n",
    "for fold ,(training_idx, validation_idx) in enumerate(time_series_split_folds.split(X,y)):\n",
    "    lstm_model = lstm_architecture(INPUT_SHAPE,LR)\n",
    "\n",
    "    X_train_cv = tf.convert_to_tensor(X[training_idx], dtype=tf.float32)\n",
    "    X_val_cv = tf.convert_to_tensor(X[validation_idx], dtype=tf.float32)\n",
    "    y_train_cv = tf.convert_to_tensor(y_scaled[training_idx], dtype=tf.float32)\n",
    "    y_val_cv = tf.convert_to_tensor(y_scaled[validation_idx], dtype=tf.float32)\n",
    "    \n",
    "    lstm_model.fit(X_train_cv,y_train_cv,epochs=EPOCHS,validation_data=(X_val_cv,y_val_cv),callbacks=CALLBACK,verbose=1)\n",
    "    val_loss, val_mae = lstm_model.evaluate(X_val_cv, y_val_cv,verbose=0)\n",
    "    \n",
    "    y_val_preds = lstm_model.predict(X_val_cv)\n",
    "    y_val_preds = scaler.inverse_transform(y_val_preds).flatten()\n",
    "    y_val_original = scaler.inverse_transform(y_val_cv.numpy().reshape(-1,1)).flatten()\n",
    "    \n",
    "    mae_original = np.mean(np.abs(y_val_preds - y_val_original))\n",
    "    \n",
    "    performance.append({\n",
    "    \"fold\": fold,\n",
    "    \"val_loss\": f'{val_loss:.4f}',\n",
    "    \"val_mae_scaled\": f'{val_mae:.4f}',\n",
    "    \"val_mae_original\": f'{mae_original:.4f}',\n",
    "    })    \n",
    "    \n",
    "    print(f'Fold {fold} , val_loss is : {val_loss:.2f}, MAE scaled is : {val_mae:.2f}, MAE original is : {mae_original:.2f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "51386a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fold val_loss val_mae_scaled val_mae_original\n",
      "0     0   0.0297         0.1538          12.7443\n",
      "1     1   0.1198         0.3350          27.9451\n",
      "2     2   0.1408         0.3541          30.6096\n"
     ]
    }
   ],
   "source": [
    "performance = pd.DataFrame(performance)\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f270ba6",
   "metadata": {},
   "source": [
    "for the lstm model , thats the max we could have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c65703",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa994644",
   "metadata": {},
   "source": [
    "#### First : Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b3a7b76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(d_model,sequence_length=3,n=10000):\n",
    "    \"\"\"\n",
    "    d_model: the dimension of our input ( output of the embedding space )\n",
    "    sequence_length: the length of our sequence for example we have 3 features then its 3\n",
    "    \"\"\"\n",
    "    PosEnc = np.zeros((sequence_length,d_model))\n",
    "    indices = np.arange(int(d_model/2))\n",
    "    positions = np.arange((sequence_length))\n",
    "    \n",
    "    for position in positions:\n",
    "        for index in indices:\n",
    "            denomenator = np.power(n,2*index/d_model)\n",
    "            PosEnc[position,2*index] = np.sin(position/denomenator)\n",
    "            PosEnc[position,2*index+1] = np.cos(position/denomenator)\n",
    "    return PosEnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e79f7075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 64)\n"
     ]
    }
   ],
   "source": [
    "d_model = 64\n",
    "sequence_length = 3\n",
    "\n",
    "PosEnc = positional_encoding(d_model,sequence_length)\n",
    "print(PosEnc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0b5210",
   "metadata": {},
   "source": [
    "- We use **the embedding** which is a way to convert raw input into a high-dimensional vector (d_model in this case).\n",
    "so our embedding vector shape is **(batch_size,time,features_embedding)**\n",
    "- **Positional encoding** is added to this embedding vector so the model knows about the position of each token or feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "13b4e070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(483, 3, 64)\n",
      "(483, 3, 64)\n"
     ]
    }
   ],
   "source": [
    "X_transformer = tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "embedded = Dense(d_model)(X_transformer)\n",
    "print(embedded.shape)\n",
    "X_embedded_positioned = embedded + PosEnc\n",
    "print(X_embedded_positioned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ead8eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
